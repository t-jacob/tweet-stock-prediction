{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vpathalam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import random  \n",
    "import string\n",
    "import bs4 as bs  \n",
    "import urllib.request  \n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import tweepy\n",
    "import TwitterCredentials as keys\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1334769458490077183\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 1333962750381486079\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 1333150005595680767\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 1332210074073378816\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 1331394712046014464\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 1330617134960009218\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 1329760170931531778\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 1328948577993957376\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 1328189842761670655\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 1327344267187150855\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 1326570387535245311\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 1325785215093018623\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 1324883047116894207\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 1324180913891270655\n",
      "...3000 tweets downloaded so far\n",
      "getting tweets before 1323659987114184707\n",
      "...3200 tweets downloaded so far\n",
      "getting tweets before 1322886161078095873\n",
      "...3238 tweets downloaded so far\n",
      "getting tweets before 1322674786640777216\n",
      "...3238 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler(keys.consumer_API_key, keys.consumer_API_secret_key)\n",
    "auth.set_access_token(keys.access_token, keys.access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "screen_name = \"wsj\"\n",
    "alltweets = []  \n",
    "new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "alltweets.extend(new_tweets)\n",
    "oldest = alltweets[-1].id - 1\n",
    "\n",
    "while len(new_tweets) > 0:\n",
    "    print(f\"getting tweets before {oldest}\")        \n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)  \n",
    "    alltweets.extend(new_tweets)\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    print(f\"...{len(alltweets)} tweets downloaded so far\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>realDonaldTrump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Status(_api=&lt;tweepy.api.API object at 0x7fac9e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Status(_api=&lt;tweepy.api.API object at 0x7fac9e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Status(_api=&lt;tweepy.api.API object at 0x7fac9e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Status(_api=&lt;tweepy.api.API object at 0x7fac9e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Status(_api=&lt;tweepy.api.API object at 0x7fac9e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3233</td>\n",
       "      <td>Status(_api=&lt;tweepy.api.API object at 0x7fac9e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3234</td>\n",
       "      <td>Status(_api=&lt;tweepy.api.API object at 0x7fac9e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3235</td>\n",
       "      <td>Status(_api=&lt;tweepy.api.API object at 0x7fac9e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3236</td>\n",
       "      <td>Status(_api=&lt;tweepy.api.API object at 0x7fac9e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3237</td>\n",
       "      <td>Status(_api=&lt;tweepy.api.API object at 0x7fac9e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3238 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        realDonaldTrump\n",
       "0     Status(_api=<tweepy.api.API object at 0x7fac9e...\n",
       "1     Status(_api=<tweepy.api.API object at 0x7fac9e...\n",
       "2     Status(_api=<tweepy.api.API object at 0x7fac9e...\n",
       "3     Status(_api=<tweepy.api.API object at 0x7fac9e...\n",
       "4     Status(_api=<tweepy.api.API object at 0x7fac9e...\n",
       "...                                                 ...\n",
       "3233  Status(_api=<tweepy.api.API object at 0x7fac9e...\n",
       "3234  Status(_api=<tweepy.api.API object at 0x7fac9e...\n",
       "3235  Status(_api=<tweepy.api.API object at 0x7fac9e...\n",
       "3236  Status(_api=<tweepy.api.API object at 0x7fac9e...\n",
       "3237  Status(_api=<tweepy.api.API object at 0x7fac9e...\n",
       "\n",
       "[3238 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"realDonaldTrump\": alltweets})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>realDonaldTrump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A government watchdog agency found no wrongdoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>“We have no conversation with other residents....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Google is deciding whether to impose severe pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Trump’s musings about running again in 2024 ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>From @WSJopinion: Continued gridlock would be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3233</td>\n",
       "      <td>It feels harder than ever to interact with peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3234</td>\n",
       "      <td>Would you buy a $2,000 dress on Amazon? That’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3235</td>\n",
       "      <td>New jobless claims fell to a seven-month low, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3236</td>\n",
       "      <td>For major sports leagues, the weirdest part of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3237</td>\n",
       "      <td>How Gap’s CEO Sonia Syngal is tackling one of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3238 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        realDonaldTrump\n",
       "0     A government watchdog agency found no wrongdoi...\n",
       "1     “We have no conversation with other residents....\n",
       "2     Google is deciding whether to impose severe pe...\n",
       "3     Trump’s musings about running again in 2024 ar...\n",
       "4     From @WSJopinion: Continued gridlock would be ...\n",
       "...                                                 ...\n",
       "3233  It feels harder than ever to interact with peo...\n",
       "3234  Would you buy a $2,000 dress on Amazon? That’s...\n",
       "3235  New jobless claims fell to a seven-month low, ...\n",
       "3236  For major sports leagues, the weirdest part of...\n",
       "3237  How Gap’s CEO Sonia Syngal is tackling one of ...\n",
       "\n",
       "[3238 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to convert the tweepy object to text\n",
    "def totext(tweet):\n",
    "    return tweet.text\n",
    "#define new data frame to hold texts of tweets\n",
    "dfnew = pd.DataFrame({\"realDonaldTrump\": []})\n",
    "#map above function to each column in df\n",
    "dfnew[\"realDonaldTrump\"] = df[\"realDonaldTrump\"].map(totext)\n",
    "dfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\n"
     ]
    }
   ],
   "source": [
    "tot = set()\n",
    "all_topics = [\"job\", \"economy\", \"trade\", \"market\", \"stock\", \"DJIA\", \"NASDAQ\", \"price\", \"jobs\", \"employed\", \"unemployed\", \"employment\", \"unemployment\", \"stock exchange\", \"bull\", \"bear\", \"market\", \"new york stock exchange\", \"shares\", \"financials\", \"taxes\", \"companies\", \"tax\", \"economic\"]\n",
    "for idx, row in dfnew.iterrows():\n",
    "    corpus = nltk.sent_tokenize(row.values[0])\n",
    "    for i in range(len(corpus)):\n",
    "        corpus[i] = corpus[i].lower()\n",
    "        corpus[i] = re.sub(r'\\W',' ',corpus[i])\n",
    "        corpus[i] = re.sub(r'\\s+',' ',corpus[i])\n",
    "        corpus[i] = re.sub(r\"http\\S+\", \"\", corpus[i])\n",
    "        corpus[i] = re.sub(r'\\w*\\d\\w*', '', corpus[i]).strip()\n",
    "        for topic in all_topics:\n",
    "            if topic in corpus[i]:\n",
    "                tot.add(corpus[i])\n",
    "print(len(tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = {}\n",
    "for sentence in tot:\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    for token in tokens:\n",
    "        if token not in wordfreq.keys():\n",
    "            wordfreq[token] = 1\n",
    "        else:\n",
    "            wordfreq[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1889"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(stopwords.words('english'))\n",
    "\n",
    "for w in set(stopwords.words('english'))  :\n",
    "    if str(w) in wordfreq:\n",
    "        del wordfreq[str(w)]\n",
    "del wordfreq['co']\n",
    "del wordfreq['u']\n",
    "#del wordfreq['trump']\n",
    "#del wordfreq['wsj']\n",
    "#del wordfreq['wsjwhatsnow']\n",
    "len(wordfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "companies: 73\n",
      "market: 46\n",
      "stocks: 36\n",
      "economy: 32\n",
      "economic: 31\n",
      "pandemic: 31\n",
      "stock: 29\n",
      "new: 27\n",
      "covid: 24\n",
      "president: 23\n",
      "biden: 23\n",
      "trade: 23\n",
      "markets: 20\n",
      "china: 19\n",
      "joe: 19\n",
      "jobs: 19\n",
      "year: 18\n",
      "week: 17\n",
      "shares: 17\n",
      "wsjwhatsnow: 16\n"
     ]
    }
   ],
   "source": [
    "d = Counter(wordfreq)\n",
    "newdict = {}\n",
    "for k, v in d.most_common(20):\n",
    "    print('%s: %i' % (k, v))\n",
    "    newdict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(newdict)), list(newdict.values()), align='center')\n",
    "plt.xticks(range(len(newdict)), list(newdict.keys()))\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "#plt.savefig('commonwords2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"white\",width=1000,height=1000, max_words=20,relative_scaling=0.5,normalize_plurals=False).generate_from_frequencies(wordfreq)\n",
    "plt.imshow(wc)\n",
    "#plt.savefig('wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target', 'ids', 'date', 'flag', 'user', 'text']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"./kaggle_dataset.csv\", \"r\", encoding = \"ISO-8859-1\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    i = next(reader)\n",
    "    rest = list(reader)\n",
    "    \n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 3000)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"kaggle_dataset.csv\", encoding = \"ISO-8859-1\", engine='python')\n",
    "target = data[\"target\"].astype(float)\n",
    "text = data[\"text\"].values\n",
    "tfv=TfidfVectorizer(min_df=0, max_features=3000, strip_accents='unicode',lowercase =True,\n",
    "                            analyzer='word', token_pattern=r'\\w{3,}', ngram_range=(1,1),\n",
    "                            use_idf=True,smooth_idf=True, sublinear_tf=True, stop_words = \"english\")   \n",
    "data=tfv.fit_transform(text)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
